<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>消息队列(MQ) | Emil`s Blog</title><meta name="keywords" content="mq"><meta name="author" content="Emil"><meta name="copyright" content="Emil"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="什么是 MQ MQ(消息队列-Message Queue)就是基础数据结构中的先进先出的一种数据机构。想一下，生活中买东西，需要排队，先排的人先买消费，就是典型的先进先出。   为什么要用消息队列  解耦 看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃…  在这个场景中，A 系统跟其它各种"><meta property="og:type" content="article"><meta property="og:title" content="消息队列(MQ)"><meta property="og:url" content="https://blog.hvnobug.com/post/mq.html"><meta property="og:site_name" content="Emil&#96;s Blog"><meta property="og:description" content="什么是 MQ MQ(消息队列-Message Queue)就是基础数据结构中的先进先出的一种数据机构。想一下，生活中买东西，需要排队，先排的人先买消费，就是典型的先进先出。   为什么要用消息队列  解耦 看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃…  在这个场景中，A 系统跟其它各种"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/36.png"><meta property="article:published_time" content="2020-07-22T05:09:10.000Z"><meta property="article:modified_time" content="2021-04-29T03:35:56.980Z"><meta property="article:author" content="Emil"><meta property="article:tag" content="mq"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/36.png"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/hvnobug/assets/common/favicon.ico"><link rel="canonical" href="https://blog.hvnobug.com/post/mq"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin="crossorigin"><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="manifest" href="/pwa/manifest.json"><meta name="msapplication-TileColor" content="#fff"><link rel="apple-touch-icon" sizes="180x180" href="/pwa/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/pwa/32.png"><link rel="icon" type="image/png" sizes="16x16" href="/pwa/16.png"><link rel="mask-icon" href="/pwa/safari-pinned-tab.svg" color="#5bbad5"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?39cbf1602bb584a9c817fbe7b061c842";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-153501439-1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-153501439-1")</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: true
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE={isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2021-04-29 11:35:56"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><style type="text/css">.app-refresh{position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease}.app-refresh-wrap{display:flex;color:#fff;height:100%;align-items:center;justify-content:center}.app-refresh-wrap a{color:#fff;text-decoration:underline;cursor:pointer}</style><style type="text/css">.app-refresh{position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease}.app-refresh-wrap{display:flex;color:#fff;height:100%;align-items:center;justify-content:center}.app-refresh-wrap span{color:#fff;text-decoration:underline;cursor:pointer}.snackbar-pos.bottom-left{bottom:70px}</style><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Emil`s Blog" type="application/atom+xml"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/common/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">56</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">34</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">32</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-sitemap"></i><span> 统计</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 媒体</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/album/"><i class="fa-fw fa fa-image"></i><span> 相册</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fa fa-book"></i><span> 书籍</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li><li><a class="site-page" href="/games/"><i class="fa-fw fa fa-gamepad"></i><span> 游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/friends/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/nav/"><i class="fa-fw fa fa-map"></i><span> 网址导航</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/36.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Emil`s Blog</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-sitemap"></i><span> 统计</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 媒体</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/album/"><i class="fa-fw fa fa-image"></i><span> 相册</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fa fa-book"></i><span> 书籍</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li><li><a class="site-page" href="/games/"><i class="fa-fw fa fa-gamepad"></i><span> 游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/friends/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/nav/"><i class="fa-fw fa fa-map"></i><span> 网址导航</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">消息队列(MQ)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-07-22T05:09:10.000Z" title="发表于 2020-07-22 13:09:10">2020-07-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-04-29T03:35:56.980Z" title="更新于 2021-04-29 11:35:56">2021-04-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/mq/">mq</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>26分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="什么是-mq"><a class="markdownIt-Anchor" href="#什么是-mq"></a> 什么是 MQ</h2><div class="note info flat"><p><code>MQ</code>(消息队列-Message Queue)就是基础数据结构中的<code>先进先出</code>的一种数据机构。想一下，生活中买东西，需要排队，先排的人先买消费，就是典型的<code>先进先出</code>。</p></div><h2 id="为什么要用消息队列"><a class="markdownIt-Anchor" href="#为什么要用消息队列"></a> 为什么要用消息队列</h2><h3 id="解耦"><a class="markdownIt-Anchor" href="#解耦"></a> 解耦</h3><p>看这么个场景。<code>A</code> 系统发送数据到 <code>BCD</code> 三个系统，通过接口调用发送。如果 <code>E</code> 系统也要这个数据呢？那如果 <code>C</code> 系统现在不需要了呢？<code>A</code> 系统负责人几乎崩溃…</p><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-1.png" alt=""></p><p>在这个场景中，<code>A</code> 系统跟其它各种乱七八糟的系统严重耦合，<code>A</code> 系统产生一条比较关键的数据，很多系统都需要 <code>A</code> 系统将这个数据发送过来。<code>A</code> 系统要时时刻刻考虑 <code>BCDE</code> 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！</p><p>如果使用 <code>MQ</code>，<code>A</code> 系统产生一条数据，发送到 <code>MQ</code> 里面去，哪个系统需要数据自己去 <code>MQ</code> 里面消费。如果新系统需要数据，直接从 <code>MQ</code> 里消费即可；如果某个系统不需要这条数据了，就取消对 <code>MQ</code> 消息的消费即可。这样下来，<code>A</code> 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。</p><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-2.png" alt=""></p><blockquote><p><strong>总结</strong>：通过一个 <code>MQ</code>，<code>Pub/Sub</code> 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。</p></blockquote><h3 id="异步"><a class="markdownIt-Anchor" href="#异步"></a> 异步</h3><p>再来看一个场景，<code>A</code> 系统接收一个请求，需要在自己本地写库，还需要在 <code>BCD</code> 三个系统写库，自己本地写库要 3ms，<code>BCD</code> 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。</p><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-3.png" alt=""></p><p>一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。</p><p>如果使用 <code>MQ</code>，那么 <code>A</code> 系统连续发送 3 条消息到 <code>MQ</code> 队列中，假如耗时 5ms，<code>A</code> 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！</p><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-4.png" alt=""></p><h3 id="削峰"><a class="markdownIt-Anchor" href="#削峰"></a> 削峰</h3><p>每天 0:00 到 12:00，<code>A</code> 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 <code>MySQL</code> 的，大量的请求涌入 <code>MySQL</code>，每秒钟对 <code>MySQL</code> 执行约 5k 条 <code>SQL</code>。</p><p>一般的 <code>MySQL</code>，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 <code>MySQL</code> 给打死了，导致系统崩溃，用户也就没法再使用系统了。</p><p>但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。</p><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-5.png" alt=""></p><p>如果使用 <code>MQ</code>，每秒 5k 个请求写入 <code>MQ</code>，<code>A</code> 系统每秒钟最多处理 2k 个请求，因为 <code>MySQL</code> 每秒钟最多处理 2k 个。<code>A</code> 系统从 <code>MQ</code> 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，<code>A</code> 系统也绝对不会挂掉。而 <code>MQ</code> 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。</p><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-6.png" alt=""></p><blockquote><p>这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 <code>MQ</code>，但是 <code>A</code> 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，<code>A</code> 系统就会快速将积压的消息给解决掉。</p></blockquote><h2 id="mq的优缺点"><a class="markdownIt-Anchor" href="#mq的优缺点"></a> MQ的优缺点</h2><blockquote><p>优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。</p></blockquote><p>缺点有以下几个:</p><ul><li>系统可用性降低</li></ul><blockquote><p>系统引入的外部依赖越多，越容易挂掉。本来你就是 <code>A</code> 系统调用 <code>BCD</code> 三个系统的接口就好了，<code>ABCD</code> 四个系统还好好的，没啥问题，你偏加个 <code>MQ</code> 进来，万一 <code>MQ</code> 挂了咋整？<code>MQ</code> 一挂，整套系统崩溃，你不就完了？如何<a href="#mq%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8">保证消息队列的高可用</a>。</p></blockquote><ul><li>系统复杂度提高</li></ul><blockquote><p>硬生生加个 MQ 进来，你怎么<a href="#mq%E7%9A%84%E5%B9%82%E7%AD%89%E6%80%A7">保证消息没有重复消费</a>？怎么<a href="#mq%E9%98%B2%E6%AD%A2%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1">处理消息丢失的情况</a>？怎么<a href="#mq%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%80%A7">保证消息传递的顺序性</a>？头大头大，问题一大堆，痛苦不已。</p></blockquote><ul><li>一致性问题</li></ul><blockquote><p><code>A</code> 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 <code>BCD</code> 三个系统那里，<code>BD</code> 两个系统写库成功了，结果 <code>C</code> 系统写库失败了，咋整？你这数据就不一致了。</p></blockquote><p>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。</p><h2 id="常见mq中间件对比"><a class="markdownIt-Anchor" href="#常见mq中间件对比"></a> 常见MQ中间件对比</h2><table><thead><tr><th>特性</th><th>ActiveMQ</th><th>RabbitMQ</th><th><a href="/post/rocketmq.html">RocketMQ</a></th><th>Kafka</th></tr></thead><tbody><tr><td>单机吞吐量</td><td>万级，比 <code>RocketMQ</code>、<code>Kafka</code> 低一个数量级</td><td>同 <code>ActiveMQ</code></td><td>10 万级，支撑高吞吐</td><td>10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td></tr><tr><td><code>topic</code> 数量对吞吐量的影响</td><td></td><td></td><td><code>topic</code> 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 <code>RocketMQ</code> 的一大优势，在同等机器下，可以支撑大量的 <code>topic</code></td><td><code>topic</code> 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，<code>Kafka</code> 尽量保证 <code>topic</code> 数量不要过多，如果要支撑大规模的 <code>topic</code>，需要增加更多的机器资源</td></tr><tr><td>时效性</td><td>ms 级</td><td>微秒级，这是 <code>RabbitMQ</code> 的一大特点，延迟最低</td><td>ms 级</td><td>延迟在 ms 级以内</td></tr><tr><td>可用性</td><td>高，基于主从架构实现高可用</td><td>同 <code>ActiveMQ</code></td><td>非常高，分布式架构</td><td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td></tr><tr><td>消息可靠性</td><td>有较低的概率丢失数据</td><td>基本不丢</td><td>经过参数优化配置，可以做到 0 丢失</td><td>同 <code>RocketMQ</code></td></tr><tr><td>功能支持</td><td><code>MQ</code> 领域的功能极其完备</td><td>基于 <code>erlang</code> 开发，并发能力很强，性能极好，延时很低</td><td><code>MQ</code> 功能较为完善，还是分布式的，扩展性好</td><td>功能较为简单，主要支持简单的 <code>MQ</code> 功能，在大数据领域的实时计算以及日志采集被大规模使用</td></tr></tbody></table><blockquote><p>一般的业务系统要引入 <code>MQ</code>，最早大家都用 <code>ActiveMQ</code>，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；<br>后来大家开始用 <code>RabbitMQ</code>，但是确实 <code>erlang</code> 语言阻止了大量的 <code>Java</code> 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；<br>不过现在确实越来越多的公司会去用 <code>RocketMQ</code>，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 <code>RocketMQ</code> 已捐给 <code>Apache</code>，但 <code>GitHub</code> 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 <code>RocketMQ</code>，否则回去老老实实用 <code>RabbitMQ</code> 吧，人家有活跃的开源社区，绝对不会黄。<br>所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 <code>RabbitMQ</code> 是不错的选择；大型公司，基础架构研发实力较强，用 <code>RocketMQ</code> 是很好的选择。<br>如果是大数据领域的实时计算、日志采集等场景，用 <code>Kafka</code> 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</p></blockquote><h2 id="mq的高可用"><a class="markdownIt-Anchor" href="#mq的高可用"></a> MQ的高可用</h2><h3 id="rabbitmq-的高可用性"><a class="markdownIt-Anchor" href="#rabbitmq-的高可用性"></a> RabbitMQ 的高可用性</h3><div class="note info flat"><p><code>RabbitMQ</code> 是比较有代表性的，因为是<code>基于主从</code>（非分布式）做高可用性的，我们就以 <code>RabbitMQ</code> 为例子讲解第一种 <code>MQ</code> 的高可用性怎么实现。<br><code>RabbitMQ</code> 有三种模式：<strong>单机模式</strong>、<strong>普通集群模式</strong>、<strong>镜像集群模式</strong>。</p></div><h4 id="单机模式"><a class="markdownIt-Anchor" href="#单机模式"></a> 单机模式</h4><p>单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的 😄，没人生产用单机模式。</p><h4 id="普通集群模式无高可用性"><a class="markdownIt-Anchor" href="#普通集群模式无高可用性"></a> 普通集群模式（无高可用性）</h4><p>普通集群模式，意思就是在多台机器上启动多个 <code>RabbitMQ</code> 实例，每个机器启动一个。你创建的 <code>queue</code>，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 <code>queue</code> 的元数据（元数据可以认为是 <code>queue</code> 的一些配置信息，通过元数据，可以找到 <code>queue</code> 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 <code>queue</code> 所在实例上拉取数据过来。<br><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-7.png" alt=""></p><p>这种方式确实很麻烦，也不怎么好，没做到所谓的<strong>分布式</strong>，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 <code>queue</code> 所在实例消费数据，前者有<strong>数据拉取的开销</strong>，后者导致<strong>单实例性能瓶颈</strong>。</p><p>而且如果那个放 <code>queue</code> 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让 <code>RabbitMQ</code> 落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 <code>queue</code> 拉取数据。</p><p>所以这个事儿就比较尴尬了，这就没有什么所谓的<strong>高可用性</strong>，这方案主要是<strong>提高吞吐量</strong>的，就是说让集群中多个节点来服务某个 <code>queue</code> 的读写操作。</p><h4 id="镜像集群模式高可用性"><a class="markdownIt-Anchor" href="#镜像集群模式高可用性"></a> 镜像集群模式（高可用性）</h4><p>这种模式，才是所谓的 <code>RabbitMQ</code> 的<strong>高可用模式</strong>。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 <code>queue</code> 里的消息都会存在于多个实例上，就是说，每个 <code>RabbitMQ</code> 节点都有这个 <code>queue</code> 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 <code>queue</code> 的时候，都会自动把消息同步到多个实例的 <code>queue</code> 上。</p><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-8.png" alt=""></p><p>那么如何开启这个<strong>镜像集群模式</strong>呢？其实很简单，<code>RabbitMQ</code> 有很好的管理控制台，就是在后台新增一个策略，这个策略是<strong>镜像集群模式的策略</strong>，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 <code>queue</code> 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p><p>这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 <code>queue</code> 的完整数据，别的 <code>consumer</code> 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就<strong>没有扩展性可言</strong>了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并<strong>没有办法线性扩展</strong>你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？</p><h3 id="kafka-的高可用性"><a class="markdownIt-Anchor" href="#kafka-的高可用性"></a> Kafka 的高可用性</h3><p><code>Kafka</code> 一个最基本的架构认识：由多个 <code>broker</code> 组成，每个 <code>broker</code> 是一个节点；你创建一个 <code>topic</code>，这个 <code>topic</code> 可以划分为多个 <code>partition</code>，每个 <code>partition</code> 可以存在于不同的 <code>broker</code> 上，每个 <code>partition</code> 就放一部分数据。<br>这就是天然的<strong>分布式消息队列</strong>，就是说一个 <code>topic</code> 的数据，是分散放在多个机器上的，每个机器就放一部分数据。<br>实际上 <code>RabbitMQ</code> 之类的，并不是<strong>分布式消息队列</strong>，它就是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性) 的机制而已，因为无论怎么玩儿，<code>RabbitMQ</code> 一个 <code>queue</code> 的数据都是放在一个节点里的，<strong>镜像集群</strong>下，也是每个节点都放这个 <code>queue</code> 的完整数据。<br><code>Kafka</code> 0.8 以前，是没有 <code>HA</code> 机制的，就是任何一个 <code>broker</code> 宕机了，那个 <code>broker</code> 上的 <code>partition</code> 就废了，没法写也没法读，没有什么高可用性可言。<br>比如说，我们假设创建了一个 <code>topic</code>，指定其 <code>partition</code> 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 <code>topic</code> 的 1/3 的数据就丢了，因此这个是做不到高可用的。<br><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/kafka-before.png" alt=""></p><p><code>Kafka</code> 0.8 以后，提供了 <code>HA</code> 机制，就是 <code>replica</code>（复制品） 副本机制。每个 <code>partition</code> 的数据都会同步到其它机器上，形成自己的多个 <code>replica</code> 副本。所有 <code>replica</code> 会选举一个 <code>leader</code> 出来，那么生产和消费都跟这个 <code>leader</code> 打交道，然后其他 <code>replica</code> 就是 <code>follower</code>。写的时候，<code>leader</code> 会负责把数据同步到所有 <code>follower</code> 上去，读的时候就直接读 <code>leader</code> 上的数据即可。只能读写 <code>leader</code>？很简单，要是你可以随意读写每个 <code>follower</code>，那么就要 <code>care</code> 数据一致性的问题，系统复杂度太高，很容易出问题。<code>Kafka</code> 会均匀地将一个 <code>partition</code> 的所有 <code>replica</code> 分布在不同的机器上，这样才可以提高<strong>容错性</strong>。<br><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/kafka-after.png" alt=""></p><p>这么搞，就有所谓的<strong>高可用性</strong>了，因为如果某个 <code>broker</code> 宕机了，没事儿，那个 <code>broker</code> 上面的 <code>partition</code> 在其他机器上都有副本的。如果这个宕机的 <code>broker</code> 上面有某个 <code>partition</code> 的 <code>leader</code>，那么此时会从 <code>follower</code> 中重新选举一个新的 <code>leader</code> 出来，大家继续读写那个新的 <code>leader</code> 即可。这就有所谓的高可用性了。</p><p><strong>写数据</strong>的时候，生产者就写 <code>leader</code>，然后 <code>leader</code> 将数据落地写本地磁盘，接着其他 <code>follower</code> 自己主动从 <code>leader</code> 来 <code>pull</code> 数据。一旦所有 <code>follower</code> 同步好数据了，就会发送 ack 给 <code>leader</code>，<code>leader</code> 收到所有 <code>follower</code> 的 <code>ack</code> 之后，就会返回写成功的消息给<strong>生产者</strong>。（当然，这只是其中一种模式，还可以适当调整这个行为）</p><p>消费的时候，只会从 <code>leader</code> 去读，但是只有当一个消息已经被所有 <code>follower</code> 都同步成功返回 <code>ack</code> 的时候，这个消息才会被消费者读到。</p><h2 id="mq的幂等性"><a class="markdownIt-Anchor" href="#mq的幂等性"></a> MQ的幂等性</h2><blockquote><p><code>RabbitMQ</code>、<code>RocketMQ</code>、<code>Kafka</code>，都有可能会出现消息重复消费的问题，正常。因为这问题通常不是 <code>MQ</code> 自己保证的，是由我们开发来保证的。挑一个 <code>Kafka</code> 来举个例子，说说怎么重复消费吧。</p></blockquote><p>重复消费的问题是由开发者去解决，而不是MQ去解决。重点在消费者，由消费者，也就是<code>MQ</code>客户端去解决。</p><p>其实还是得结合业务来思考，给出几个思路：</p><ul><li>比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，<code>update</code> 一下好吧。</li><li>比如你是写 <code>Redis</code>，那没问题了，反正每次都是 <code>set</code>，天然幂等性。</li><li>比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 <code>id</code>，类似订单 <code>id</code> 之类的东西，然后你这里消费到了之后，先根据这个 <code>id</code> 去比如 <code>Redis</code> 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 <code>id</code> 写 <code>Redis</code>。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。</li><li>比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。</li></ul><h2 id="mq的顺序性"><a class="markdownIt-Anchor" href="#mq的顺序性"></a> MQ的顺序性</h2><p>我举个例子，我们以前做过一个 <code>mysql</code> <code>binlog</code> 同步的系统，压力还是非常大的，日同步数据要达到上亿，就是说数据从一个 mysql 库原封不动地同步到另一个 mysql 库里面去（<code>mysql</code> -&gt; <code>mysql</code>）。常见的一点在于说比如大数据 <code>team</code>，就需要同步一个 <code>mysql</code> 库过来，对公司的业务系统的数据做各种复杂的操作。</p><p>你在 <code>mysql</code> 里增删改一条数据，对应出来了增删改 3 条 <code>binlog</code> 日志，接着这三条 <code>binlog</code> 发送到 <code>MQ</code> 里面，再消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你愣是换了顺序给执行成删除、修改、增加，不全错了么。</p><p>本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。</p><p>先看看顺序会错乱的俩场景：</p><ul><li><strong>RabbitMQ</strong>: 一个 <code>queue</code>，多个 <code>consumer</code>。比如，生产者向 <code>RabbitMQ</code> 里发送了三条数据，顺序依次是 <strong>data1/data2/data3</strong>，压入的是 <code>RabbitMQ</code> 的一个内存队列。有三个消费者分别从 <code>MQ</code> 中消费这三条数据中的一条，结果消费者 2 先执行完操作，把 <strong>data2</strong> 存入数据库，然后是 <strong>data1/data3</strong>。这不明显乱了。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/rabbitmq-order-01.png" alt=""></p><ul><li><strong>Kafka</strong>: 比如说我们建了一个 <code>topic</code>，有三个 <code>partition</code>。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 <code>partition</code> 中去，而且这个 <code>partition</code> 中的数据一定是有顺序的。</li></ul><p>消费者从 <code>partition</code> 中取出来数据的时候，也一定是<strong>有顺序的</strong>。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞<strong>多个线程来并发处理消息</strong>。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。</p><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/kafka-order-01.png" alt=""></p><h3 id="rabbitmq"><a class="markdownIt-Anchor" href="#rabbitmq"></a> RabbitMQ</h3><ul><li>一个 <code>topic</code>，一个 <code>partition</code>，一个 <code>consumer</code>，内部单线程消费，单线程吞吐量太低，一般不会用这个。</li><li>写 N 个内存 <code>queue</code>，具有相同 <code>key</code> 的数据都到同一个内存 <code>queue</code>；然后对于 N 个线程，每个线程分别消费一个内存 <code>queue</code> 即可，这样就能保证顺序性。<br><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/kafka-order-02.png" alt=""></li></ul><h3 id="kafka"><a class="markdownIt-Anchor" href="#kafka"></a> Kafka</h3><p><code>kafka</code>一个<code>topic</code>，一个<code>partition</code>，一个<code>consumer</code>，但是<code>consumer</code>内部进行多线程消费，这样数据也会出现顺序错乱问题。</p><h2 id="mq防止消息丢失"><a class="markdownIt-Anchor" href="#mq防止消息丢失"></a> MQ防止消息丢失</h2><h3 id="rabbitmq-2"><a class="markdownIt-Anchor" href="#rabbitmq-2"></a> RabbitMQ</h3><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/rabbitmq-message-lose.png" alt=""></p><h4 id="生产者弄丢了数据"><a class="markdownIt-Anchor" href="#生产者弄丢了数据"></a> 生产者弄丢了数据</h4><p>生产者将数据发送到 <code>RabbitMQ</code> 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。</p><p>此时可以选择用 <code>RabbitMQ</code> 提供的事务功能，就是生产者发送数据之前开启 RabbitMQ 事务 channel.txSelect ，然后发送消息，如果消息没有成功被 <code>RabbitMQ</code> 接收到，那么生产者会收到异常报错，此时就可以回滚事务 <code>channel.txRollback</code> ，然后重试发送消息；如果收到了消息，那么可以提交事务 <code>channel.txCommit</code> 。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启事务</span></span><br><span class="line">channel.txSelect</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 这里发送消息</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    channel.txRollback</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里再次重发这条消息</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 提交事务</span></span><br><span class="line">channel.txCommit</span><br></pre></td></tr></table></figure><p>但是问题是，<code>RabbitMQ</code> 事务机制（同步）一搞，基本上<strong>吞吐量会下来，因为太耗性能</strong>。</p><p>所以一般来说，如果你要确保说写 <code>RabbitMQ</code> 的消息别丢，可以开启 <code>confirm</code> 模式，在生产者那里设置开启 <code>confirm</code> 模式之后，你每次写的消息都会分配一个唯一的 <code>id</code>，然后如果写入了 <code>RabbitMQ</code> 中，<code>RabbitMQ</code> 会给你回传一个 <code>ack</code> 消息，告诉你说这个消息 <code>ok</code> 了。如果 <code>RabbitMQ</code> 没能处理这个消息，会回调你的一个 <code>nack</code> 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 <code>id</code> 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p><p>事务机制和 <code>confirm</code> 机制最大的不同在于，<strong>事务机制是同步</strong>的，你提交一个事务之后会阻塞在那儿，但是 <code>confirm</code> 机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息 <code>RabbitMQ</code> 接收了之后会异步回调你的一个接口通知你这个消息接收到了。</p><p>所以一般在生产者这块<strong>避免数据丢失</strong>，都是用 <code>confirm</code> 机制的。</p><h4 id="rabbitmq-弄丢了数据"><a class="markdownIt-Anchor" href="#rabbitmq-弄丢了数据"></a> RabbitMQ 弄丢了数据</h4><p>就是 <code>RabbitMQ</code> 自己弄丢了数据，这个你必须开启 <code>RabbitMQ</code> 的<strong>持久化</strong>，就是消息写入之后会持久化到磁盘，哪怕是 <code>RabbitMQ</code> 自己挂了，<strong>恢复之后会自动读取之前存储的数据</strong>，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，<strong>可能导致少量数据丢失</strong>，但是这个概率较小。</p><p>设置持久化有两个步骤：</p><ul><li><p>创建 <code>queue</code> 的时候将其设置为持久化<br>这样就可以保证 <code>RabbitMQ</code> 持久化 <code>queue</code> 的元数据，但是它是不会持久化 <code>queue</code> 里的数据的。</p></li><li><p>第二个是发送消息的时候将消息的 <code>deliveryMode</code> 设置为 2<br>就是将消息设置为持久化的，此时 <code>RabbitMQ</code> 就会将消息持久化到磁盘上去。</p></li></ul><p>必须要同时设置这两个持久化才行，<code>RabbitMQ</code> 哪怕是挂了，再次重启，也会从磁盘上重启恢复 <code>queue</code>，恢复这个 <code>queue</code> 里的数据。</p><p>注意，哪怕是你给 <code>RabbitMQ</code> 开启了持久化机制，也有一种可能，就是这个消息写到了 <code>RabbitMQ</code> 中，但是还没来得及持久化到磁盘上，结果不巧，此时 <code>RabbitMQ</code> 挂了，就会导致内存里的一点点数据丢失。</p><p>所以，持久化可以跟生产者那边的 <code>confirm</code> 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 <code>ack</code> 了，所以哪怕是在持久化到磁盘之前，<code>RabbitMQ</code> 挂了，数据丢了，生产者收不到 <code>ack</code> ，你也是可以自己重发的。</p><h4 id="消费端弄丢了数据"><a class="markdownIt-Anchor" href="#消费端弄丢了数据"></a> 消费端弄丢了数据</h4><p><code>RabbitMQ</code> 如果丢失了数据，主要是因为你消费的时候，<strong>刚消费到，还没处理，结果进程挂了</strong>，比如重启了，那么就尴尬了，<code>RabbitMQ</code> 认为你都消费了，这数据就丢了。</p><p>这个时候得用 <code>RabbitMQ</code> 提供的 <code>ack</code> 机制，简单来说，就是你必须关闭 <code>RabbitMQ</code> 的自动 <code>ack</code> ，可以通过一个 <code>api</code> 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 <code>ack</code> 一把。这样的话，如果你还没处理完，不就没有 <code>ack</code> 了？那 <code>RabbitMQ</code> 就认为你还没处理完，这个时候 <code>RabbitMQ</code> 会把这个消费分配给别的 <code>consumer</code> 去处理，消息是不会丢的。</p><p><img src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/loading/11.gif" data-lazy-src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/rabbitmq-message-lose-solution.png" alt=""></p><h3 id="kafka-2"><a class="markdownIt-Anchor" href="#kafka-2"></a> Kafka</h3><h4 id="消费端弄丢了数据-2"><a class="markdownIt-Anchor" href="#消费端弄丢了数据-2"></a> 消费端弄丢了数据</h4><p>唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边<strong>自动提交</strong>了 <code>offset</code>，让 <code>Kafka</code> 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p><p>这不是跟 <code>RabbitMQ</code> 差不多吗，大家都知道 <code>Kafka</code> 会自动提交 <code>offset</code>，那么只要<strong>关闭自动提交</strong> <code>offset</code>，在处理完之后自己手动提交 <code>offset</code>，就可以保证数据不会丢。但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 <code>offset</code>，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p><p>生产环境碰到的一个问题，就是说我们的 <code>Kafka</code> 消费者消费到了数据之后是写到一个内存的 <code>queue</code> 里先缓冲一下，结果有的时候，你刚把消息写入内存 <code>queue</code>，然后消费者会自动提交 <code>offset</code>。然后此时我们重启了系统，就会导致内存 <code>queue</code> 里还没来得及处理的数据就丢失了。</p><h4 id="kafka-弄丢了数据"><a class="markdownIt-Anchor" href="#kafka-弄丢了数据"></a> Kafka 弄丢了数据</h4><p>这块比较常见的一个场景，就是 <code>Kafka</code> 某个 <code>broker</code> 宕机，然后重新选举 <code>partition</code> 的 <code>leader</code>。大家想想，要是此时其他的 <code>follower</code> 刚好还有些数据没有同步，结果此时 <code>leader</code> 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。</p><p>生产环境也遇到过，我们也是，之前 <code>Kafka</code> 的 <code>leader</code> 机器宕机了，将 <code>follower</code> 切换为 <code>leader</code> 之后，就会发现说这个数据就丢了。</p><p>所以此时一般是要求起码设置如下 4 个参数：</p><ul><li>给 <code>topic</code> 设置 <code>replication.factor</code> 参数：这个值必须大于 1，要求每个 <code>partition</code> 必须有至少 2 个副本。</li><li>在 <code>Kafka</code> 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 1，这个是要求一个 <code>leader</code> 至少感知到有至少一个 <code>follower</code> 还跟自己保持联系，没掉队，这样才能确保 <code>leader</code> 挂了还有一个 <code>follower</code> 吧。</li><li>在 <code>producer</code> 端设置 <code>acks=all</code> ：这个是要求每条数据，必须是写入所有 <code>replica</code> 之后，才能认为是写成功了。</li><li>在 <code>producer</code> 端设置 <code>retries=MAX</code> （很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。</li></ul><p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在 <code>Kafka broker</code> 端就可以保证在 <code>leader</code> 所在 <code>broker</code> 发生故障，进行 <code>leader</code> 切换时，数据不会丢失。</p><h4 id="生产者会不会弄丢数据"><a class="markdownIt-Anchor" href="#生产者会不会弄丢数据"></a> 生产者会不会弄丢数据？</h4><p>如果按照上述的思路设置了 <code>acks=all</code> ，一定不会丢，要求是，你的 <code>leader</code> 接收到消息，所有的 <code>follower</code> 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p><h2 id="消息队列的延时以及过期失效问题"><a class="markdownIt-Anchor" href="#消息队列的延时以及过期失效问题"></a> 消息队列的延时以及过期失效问题</h2><h3 id="大量消息积压"><a class="markdownIt-Anchor" href="#大量消息积压"></a> 大量消息积压</h3><p>几千万条数据在 <code>MQ</code> 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 <code>consumer</code> 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。</p><p>一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。</p><p>一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：</p><ul><li>先修复 <code>consumer</code> 的问题，确保其恢复消费速度，然后将现有 <code>consumer</code> 都停掉。</li><li>新建一个 <code>topic</code>，<code>partition</code> 是原来的 10 倍，临时建立好原先 10 倍的 <code>queue</code> 数量。</li><li>然后写一个临时的分发数据的 <code>consumer</code> 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 <code>queue</code>。</li><li>接着临时征用 10 倍的机器来部署 <code>consumer</code>，每一批 <code>consumer</code> 消费一个临时 <code>queue</code> 的数据。这种做法相当于是临时将 <code>queue</code> 资源和 <code>consumer</code> 资源扩大 10 倍，以正常的 10 倍速度来消费数据。</li><li>等快速消费完积压数据之后，得<strong>恢复原先部署的架构</strong>，重新用原先的 <code>consumer</code> 机器来消费消息。</li></ul><h3 id="消息过期失效"><a class="markdownIt-Anchor" href="#消息过期失效"></a> 消息过期失效</h3><p>假设你用的是 <code>RabbitMQ</code>，<code>RabbtiMQ</code> 是可以设置过期时间的，也就是 <code>TTL</code>。如果消息在 <code>queue</code> 中积压超过一定的时间就会被 <code>RabbitMQ</code> 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 <code>mq</code> 里，而是<strong>大量的数据会直接搞丢</strong>。</p><p>这个情况下，就不是说要增加 <code>consumer</code> 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 <code>mq</code> 里面去，把白天丢的数据给他补回来。也只能是这样了。</p><p>假设 1 万个订单积压在 <code>mq</code> 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 <code>mq</code> 里去再补一次。</p><h3 id="mq-都快写满了"><a class="markdownIt-Anchor" href="#mq-都快写满了"></a> mq 都快写满了</h3><p>如果消息积压在 <code>mq</code> 里，你很长时间都没有处理掉，此时导致 <code>mq</code> 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。</p><h3 id="rocketmq-消息积压"><a class="markdownIt-Anchor" href="#rocketmq-消息积压"></a> RocketMq 消息积压</h3><h4 id="提高消费并行度"><a class="markdownIt-Anchor" href="#提高消费并行度"></a> 提高消费并行度</h4><p>绝大部分消息消费行为都属于 <code>IO</code> 密集型，即可能是操作数据库，或者调用 <code>RPC</code>，这类消费行为的消费速度在于后端数据库或者外系统的吞吐量，通过增加消费并行度，可以提高总的消费吞吐量，但是并行度增加到一定程度，反而会下降。所以，应用必须要设置合理的并行度。 如下有几种修改消费并行度的方法：</p><p>同一个 <code>ConsumerGroup</code> 下，通过增加 <code>Consumer</code> 实例数量来提高并行度（需要注意的是超过订阅队列数的 <code>Consumer</code> 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。 提高单个 <code>Consumer</code> 的消费并行线程，通过修改参数 <code>consumeThreadMin</code>、<code>consumeThreadMax</code> 实现。</p><h4 id="批量方式消费"><a class="markdownIt-Anchor" href="#批量方式消费"></a> 批量方式消费</h4><p>某些业务流程如果支持批量方式消费，则可以很大程度上提高消费吞吐量，例如订单扣款类应用，一次处理一个订单耗时 1 s，一次处理 10 个订单可能也只耗时 2 s，这样即可大幅度提高消费的吞吐量，通过设置 <code>consumer</code> 的 <code>consumeMessageBatchMaxSize</code> 返个参数，默认是 1，即一次只消费一条消息，例如设置为 N，那么每次消费的消息数小于等于 N。</p><h4 id="跳过非重要消息"><a class="markdownIt-Anchor" href="#跳过非重要消息"></a> 跳过非重要消息</h4><p>发生消息堆积时，如果消费速度一直追不上发送速度，如果业务对数据要求不高的话，可以选择丢弃不重要的消息。例如，当某个队列的消息数堆积到 100000 条以上，则尝试丢弃部分或全部消息，这样就可以快速追上发送消息的速度。示例代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            List&lt;MessageExt&gt; msgs,</span></span></span><br><span class="line"><span class="function"><span class="params">            ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> offset = msgs.get(<span class="number">0</span>).getQueueOffset();</span><br><span class="line">    String maxOffset =</span><br><span class="line">            msgs.get(<span class="number">0</span>).getProperty(Message.PROPERTY_MAX_OFFSET);</span><br><span class="line">    <span class="keyword">long</span> diff = Long.parseLong(maxOffset) - offset;</span><br><span class="line">    <span class="keyword">if</span> (diff &gt; <span class="number">100000</span>) &#123;</span><br><span class="line">        <span class="comment">// TODO 消息堆积情况的特殊处理</span></span><br><span class="line">        <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// TODO 正常消费过程</span></span><br><span class="line">    <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="优化每条消息消费过程"><a class="markdownIt-Anchor" href="#优化每条消息消费过程"></a> 优化每条消息消费过程</h4><p>举例如下，某条消息的消费过程如下：</p><ul><li>根据消息从 DB 查询【数据 1】</li><li>根据消息从 DB 查询【数据 2】</li><li>复杂的业务计算</li><li>向 DB 插入【数据 3】</li><li>向 DB 插入【数据 4】</li></ul><p>这条消息的消费过程中有 4 次与 DB 的 交互，如果按照每次 5ms 计算，那么总共耗时 20ms，假设业务计算耗时 5ms，那么总过耗时 25ms，所以如果能把 4 次 DB 交互优化为 2 次，那么总耗时就可以优化到 15ms，即总体性能提高了 40%。所以应用如果对时延敏感的话，可以把 DB 部署在 SSD 硬盘，相比于 SCSI 磁盘，前者的 RT 会小很多。</p><p>关于<code>RocketMq</code> 文档<a target="_blank" rel="noopener" href="http://hvnobug.com/pages/document/rocketmq/">请点击这里</a></p><p>本文转自<a target="_blank" rel="noopener" href="https://doocs.github.io/advanced-java/#/./docs/high-concurrency/mq-interview">advanced-java | 消息队列面试场景</a></p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Emil</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://blog.hvnobug.com/post/mq.html">https://blog.hvnobug.com/post/mq.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.hvnobug.com" target="_blank">Emil`s Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/mq/">mq</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/36.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/medias/reward/wechat.png" target="_blank"><img class="post-qr-code-img" data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/medias/reward/wechat.png" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/medias/reward/alipay.jpg" target="_blank"><img class="post-qr-code-img" data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/medias/reward/alipay.jpg" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/post/rocketmq.html"><img class="prev-cover" data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/38.png" onerror='onerror=null,src="/img/404.jpg"'><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">RocketMQ</div></div></a></div><div class="next-post pull-right"><a href="/post/user-mode-linux.html"><img class="next-cover" data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/35.png" onerror='onerror=null,src="/img/404.jpg"'><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">User Mode Linux(UML-用户态方式运行Linux内核)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/post/rocketmq.html" title="RocketMQ"><img class="cover" data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/38.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-03</div><div class="title">RocketMQ</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/common/avatar.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"><div class="author-info__name">Emil</div><div class="author-info__description">Emil`s Blog 是 Hexo 建造的个人博客网站.Java 第三方开源框架源码. 其他语言技术分享. 个人博客搭建.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">56</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">34</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">32</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/hvnobug/" target="_blank"><i class="fa fa-github"></i></a><a class="social-icon" href="mailto:972080809@qq.com" target="_blank"><i class="fa fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank"><i class="fa fa-rss"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">感谢访问本站,若喜欢请收藏 ^_^</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-mq"><span class="toc-number">1.</span> <span class="toc-text">什么是 MQ</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="toc-number">2.</span> <span class="toc-text">为什么要用消息队列</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E8%80%A6"><span class="toc-number">2.1.</span> <span class="toc-text">解耦</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5"><span class="toc-number">2.2.</span> <span class="toc-text">异步</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8A%E5%B3%B0"><span class="toc-number">2.3.</span> <span class="toc-text">削峰</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mq%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">3.</span> <span class="toc-text">MQ的优缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81mq%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%AF%B9%E6%AF%94"><span class="toc-number">4.</span> <span class="toc-text">常见MQ中间件对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mq%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="toc-number">5.</span> <span class="toc-text">MQ的高可用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rabbitmq-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="toc-number">5.1.</span> <span class="toc-text">RabbitMQ 的高可用性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F"><span class="toc-number">5.1.1.</span> <span class="toc-text">单机模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%99%AE%E9%80%9A%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E6%97%A0%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="toc-number">5.1.2.</span> <span class="toc-text">普通集群模式（无高可用性）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%95%9C%E5%83%8F%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="toc-number">5.1.3.</span> <span class="toc-text">镜像集群模式（高可用性）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="toc-number">5.2.</span> <span class="toc-text">Kafka 的高可用性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mq%E7%9A%84%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-number">6.</span> <span class="toc-text">MQ的幂等性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mq%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%80%A7"><span class="toc-number">7.</span> <span class="toc-text">MQ的顺序性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rabbitmq"><span class="toc-number">7.1.</span> <span class="toc-text">RabbitMQ</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka"><span class="toc-number">7.2.</span> <span class="toc-text">Kafka</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mq%E9%98%B2%E6%AD%A2%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="toc-number">8.</span> <span class="toc-text">MQ防止消息丢失</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rabbitmq-2"><span class="toc-number">8.1.</span> <span class="toc-text">RabbitMQ</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%BC%84%E4%B8%A2%E4%BA%86%E6%95%B0%E6%8D%AE"><span class="toc-number">8.1.1.</span> <span class="toc-text">生产者弄丢了数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rabbitmq-%E5%BC%84%E4%B8%A2%E4%BA%86%E6%95%B0%E6%8D%AE"><span class="toc-number">8.1.2.</span> <span class="toc-text">RabbitMQ 弄丢了数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E7%AB%AF%E5%BC%84%E4%B8%A2%E4%BA%86%E6%95%B0%E6%8D%AE"><span class="toc-number">8.1.3.</span> <span class="toc-text">消费端弄丢了数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka-2"><span class="toc-number">8.2.</span> <span class="toc-text">Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E7%AB%AF%E5%BC%84%E4%B8%A2%E4%BA%86%E6%95%B0%E6%8D%AE-2"><span class="toc-number">8.2.1.</span> <span class="toc-text">消费端弄丢了数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#kafka-%E5%BC%84%E4%B8%A2%E4%BA%86%E6%95%B0%E6%8D%AE"><span class="toc-number">8.2.2.</span> <span class="toc-text">Kafka 弄丢了数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%BC%9A%E4%B8%8D%E4%BC%9A%E5%BC%84%E4%B8%A2%E6%95%B0%E6%8D%AE"><span class="toc-number">8.2.3.</span> <span class="toc-text">生产者会不会弄丢数据？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%BB%B6%E6%97%B6%E4%BB%A5%E5%8F%8A%E8%BF%87%E6%9C%9F%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98"><span class="toc-number">9.</span> <span class="toc-text">消息队列的延时以及过期失效问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%A7%E9%87%8F%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B"><span class="toc-number">9.1.</span> <span class="toc-text">大量消息积压</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E8%BF%87%E6%9C%9F%E5%A4%B1%E6%95%88"><span class="toc-number">9.2.</span> <span class="toc-text">消息过期失效</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mq-%E9%83%BD%E5%BF%AB%E5%86%99%E6%BB%A1%E4%BA%86"><span class="toc-number">9.3.</span> <span class="toc-text">mq 都快写满了</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rocketmq-%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B"><span class="toc-number">9.4.</span> <span class="toc-text">RocketMq 消息积压</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8F%90%E9%AB%98%E6%B6%88%E8%B4%B9%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="toc-number">9.4.1.</span> <span class="toc-text">提高消费并行度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%B9%E9%87%8F%E6%96%B9%E5%BC%8F%E6%B6%88%E8%B4%B9"><span class="toc-number">9.4.2.</span> <span class="toc-text">批量方式消费</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B7%B3%E8%BF%87%E9%9D%9E%E9%87%8D%E8%A6%81%E6%B6%88%E6%81%AF"><span class="toc-number">9.4.3.</span> <span class="toc-text">跳过非重要消息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%AF%8F%E6%9D%A1%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E8%BF%87%E7%A8%8B"><span class="toc-number">9.4.4.</span> <span class="toc-text">优化每条消息消费过程</span></a></li></ol></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/concurrent-phaser.html" title="并发编程 - Phaser"><img data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/58.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="并发编程 - Phaser"></a><div class="content"><a class="title" href="/post/concurrent-phaser.html" title="并发编程 - Phaser">并发编程 - Phaser</a><time datetime="2021-04-07T14:13:12.000Z" title="发表于 2021-04-07 22:13:12">2021-04-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/concurrent-semaphore.html" title="并发编程 - Semaphore"><img data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/57.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="并发编程 - Semaphore"></a><div class="content"><a class="title" href="/post/concurrent-semaphore.html" title="并发编程 - Semaphore">并发编程 - Semaphore</a><time datetime="2021-04-03T05:33:27.000Z" title="发表于 2021-04-03 13:33:27">2021-04-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/concurrent-cyclicbarrier.html" title="并发编程 - CyclicBarrier"><img data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/56.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="并发编程 - CyclicBarrier"></a><div class="content"><a class="title" href="/post/concurrent-cyclicbarrier.html" title="并发编程 - CyclicBarrier">并发编程 - CyclicBarrier</a><time datetime="2021-03-27T02:23:57.000Z" title="发表于 2021-03-27 10:23:57">2021-03-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/concurrent-countdownlatch.html" title="并发编程 - CountDownLatch"><img data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/54.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="并发编程 - CountDownLatch"></a><div class="content"><a class="title" href="/post/concurrent-countdownlatch.html" title="并发编程 - CountDownLatch">并发编程 - CountDownLatch</a><time datetime="2021-03-20T12:13:12.000Z" title="发表于 2021-03-20 20:13:12">2021-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/concurrent-reentrantreadwritelock.html" title="并发编程 - ReentrantReadWriteLock"><img data-lazy-src="https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/54.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="并发编程 - ReentrantReadWriteLock"></a><div class="content"><a class="title" href="/post/concurrent-reentrantreadwritelock.html" title="并发编程 - ReentrantReadWriteLock">并发编程 - ReentrantReadWriteLock</a><time datetime="2021-03-12T05:21:53.000Z" title="发表于 2021-03-12 13:21:53">2021-03-12</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(https://cdn.jsdelivr.net/gh/hvnobug/assets/blog/album/original-anime/0.png)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Emil</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49b1f5">hexo-generator-search</a> <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'wN7GK2Jgd6fz8so4U85XeUxl-9Nh9j0Va',
      appKey: 'JRpha8sPFNqXkv1a0HNIIQFY',
      placeholder: '说点什么吧 ...!',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: true,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: true,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div class="app-refresh" id="app-refresh"><div class="app-refresh-wrap"><label>✨ 网站已更新最新版本 👉</label> <a href="javascript:void(0)" onclick="location.reload()">點擊刷新</a></div></div><script>function showNotification(){if(GLOBAL_CONFIG.Snackbar){var t="light"===document.documentElement.getAttribute("data-theme")?GLOBAL_CONFIG.Snackbar.bgLight:GLOBAL_CONFIG.Snackbar.bgDark,e=GLOBAL_CONFIG.Snackbar.position;Snackbar.show({text:"已更新最新版本",backgroundColor:t,duration:5e5,pos:e,actionText:"點擊刷新",actionTextColor:"#fff",onActionClick:function(t){location.reload()}})}else{var o=`top: 0; background: ${"light"===document.documentElement.getAttribute("data-theme")?"#49b1f5":"#1f1f1f"};`;document.getElementById("app-refresh").style.cssText=o}}"serviceWorker"in navigator&&(navigator.serviceWorker.controller&&navigator.serviceWorker.addEventListener("controllerchange",function(){showNotification()}),window.addEventListener("load",function(){navigator.serviceWorker.register("/sw.js")}));</script><script src="//code.tidio.co/aksnqalq4y8zibuahby7nqeilrtcb1oi.js" async></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()</script></div><link href="//unpkg.com/aplayer/dist/APlayer.min.css" rel="stylesheet"><script src="//cdn.jsdelivr.net/npm/hls.js@latest"></script><script src="//unpkg.com/aplayer/dist/APlayer.min.js"></script><script src="/assets/aplayer.js" type="text/javascript"></script><script type="text/javascript">const $title = $('.bg-cover .title');
    if ($title.length > 0) {
        $.ajax({
            url: 'https://sdk.jinrishici.com/v2/browser/jinrishici.js',
            dataType: "script",
            cache: true,
            async: false,
            success: function () {
                jinrishici.load(function (result) {
                    // 自己的处理逻辑
                    const {status, data} = result;
                    if (status === 'success') {
                        $title.css('font-size', '3rem');
                        $title.html(data.origin.title + '<span style="font-size:2rem;margin-left:1rem;">' + data.origin.author + '-' + data.origin['dynasty'] + '</span>');
                        typed.strings = data.origin.content.slice(0, 2);
                    }
                });
            }
        });
    }</script><div class="app-refresh" id="app-refresh"><div class="app-refresh-wrap"><label>✨ 网站已更新最新版本 👉</label> <a href="javascript:void(0)" onclick="location.reload()">點擊刷新</a></div></div><script>function showNotification(){var t,e,o;GLOBAL_CONFIG.Snackbar?(t="light"===document.documentElement.getAttribute("data-theme")?GLOBAL_CONFIG.Snackbar.bgLight:GLOBAL_CONFIG.Snackbar.bgDark,e=GLOBAL_CONFIG.Snackbar.position,Snackbar.show({text:"已更新最新版本",backgroundColor:t,duration:5e5,pos:e,actionText:"点击刷新",actionTextColor:"#fff",onActionClick:function(t){location.reload()}})):(o="top: 0; background: "+("light"===document.documentElement.getAttribute("data-theme")?"#49b1f5":"#1f1f1f")+";",document.getElementById("app-refresh").style.cssText=o)}"serviceWorker"in navigator&&(navigator.serviceWorker.controller&&navigator.serviceWorker.addEventListener("controllerchange",function(){showNotification()}),window.addEventListener("load",function(){navigator.serviceWorker.register("/sw.js")}))</script><script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script><script>const hasAttr = (e,a) => a.some(_=> e.attr(_)!==undefined);
        $('a').each(function() {
          const $this = $(this);
          if(hasAttr($this,["data-fancybox","ignore-external-link"])) return;
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== '' || window.location.host) {
                    $this.attr('href', '/go.html?url='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });</script></body></html>